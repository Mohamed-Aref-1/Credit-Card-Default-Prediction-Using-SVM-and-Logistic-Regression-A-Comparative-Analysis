# -*- coding: utf-8 -*-
"""SVM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qacCKMnF0_BU6xTvhgVR-VYfNccdcnJo
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.colors as colors
from sklearn.utils import resample
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import scale
from sklearn.svm import SVC
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import confusion_matrix
from sklearn.decomposition import PCA
import seaborn as sns
from sklearn.metrics import accuracy_score
from sklearn.linear_model import LogisticRegression

df = pd.read_csv('/content/UCI_Credit_Card.csv', header=0)

df.head()

df.isnull().sum()

df.rename({'default.payment.next.month': "default"},
          axis='columns', inplace=True)
df.head()

df.drop('ID', axis=1, inplace=True)
df.head()

df.dtypes

df['MARRIAGE'].unique()

df['EDUCATION'].unique()

df['SEX'].unique()

len(df.loc[(df['MARRIAGE'] == 0)])

len(df.loc[(df['EDUCATION'] == 0)])

len(df)

df_without_missing = df.loc[(df['MARRIAGE'] != 0) & (df['EDUCATION'] != 0)]

len(df_without_missing)

df_no_default = df_without_missing[df_without_missing['default'] == 0]
print(len(df_no_default))
df_default = df_without_missing[df_without_missing['default'] == 1]
print(len(df_default))

df_no_default_downsampled = resample(
    df_no_default, replace=False, n_samples=800, random_state=2)
df_default_downsampled = resample(
    df_default, replace=False, n_samples=800, random_state=2)

df_all_downsampled = pd.concat(
    [df_no_default_downsampled, df_default_downsampled])
df_all_downsampled.shape

x = df_all_downsampled.drop('default', axis=1).copy()
x.head()

x.shape

y = df_all_downsampled['default'].copy()
y.head()

"""# One-hot encoding (convert the columns of categorical data into a multiple columns of binary values)"""

pd.get_dummies(x, columns=['SEX']).head()  # SEX column has changed

x_encoded = pd.get_dummies(x, columns=[
                           'MARRIAGE', 'EDUCATION', 'SEX', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6'])
x_encoded.head()

x_encoded.shape  # The data frame became 88 columns instead of 23

"""Split the data """

x_train, x_test, y_train, y_test = train_test_split(
    x_encoded, y, test_size=0.3, random_state=2)

x_train_scaled = scale(x_train)
x_test_scaled = scale(x_test)

model_svm = SVC(random_state=2)  # support vector classifier
model_svm.fit(x_train_scaled, y_train)
model_logestic = LogisticRegression()
model_logestic.fit(x_train_scaled, y_train)

y_pred = model_svm.predict(x_train)
y_pred_logestic = model_logestic.predict(x_train)

cm = confusion_matrix(y_train, y_pred)
print(
    f"Accuracy of the LR model is {accuracy_score(y_pred_logestic, y_train)}")
print(f"Accuracy of the SVM model is {accuracy_score(y_pred, y_train)}")


def plot_confusion_matrix(cm,
                          target_names,
                          title='Confusion matrix',
                          cmap=None,
                          normalize=True):
    """
    given a sklearn confusion matrix (cm), make a nice plot

    Arguments
    ---------
    cm:           confusion matrix from sklearn.metrics.confusion_matrix

    target_names: given classification classes such as [0, 1, 2]
                  the class names, for example: ['high', 'medium', 'low']

    title:        the text to display at the top of the matrix

    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm
                  see http://matplotlib.org/examples/color/colormaps_reference.html
                  plt.get_cmap('jet') or plt.cm.Blues

    normalize:    If False, plot the raw numbers
                  If True, plot the proportions

    Usage
    -----
    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by
                                                              # sklearn.metrics.confusion_matrix
                          normalize    = True,                # show proportions
                          target_names = y_labels_vals,       # list of names of the classes
                          title        = best_estimator_name) # title of graph

    Citiation
    ---------
    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html

    """
    import matplotlib.pyplot as plt
    import numpy as np
    import itertools

    # swap top left and top right elements
    cm[[0, 1], [1, 0]] = cm[[0, 0], [1, 0]]

    accuracy = np.trace(cm) / np.sum(cm).astype('float')
    misclass = 1 - accuracy

    if cmap is None:
        # https://matplotlib.org/3.1.1/gallery/color/colormap_reference.html
        cmap = plt.get_cmap('cool')

    plt.figure(figsize=(8, 6))
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()

    if target_names is not None:
        tick_marks = np.arange(len(target_names))
        plt.xticks(tick_marks, target_names, rotation=45)
        plt.yticks(tick_marks, target_names)

    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]

    thresh = cm.max() / 1.5 if normalize else cm.max() / 2
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        if normalize:
            plt.text(j, i, "{:0.4f}".format(cm[i, j]),
                     horizontalalignment="center",
                     color="white" if cm[i, j] > thresh else "black")
        else:
            plt.text(j, i, "{:,}".format(cm[i, j]),
                     horizontalalignment="center",
                     color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label\naccuracy={:0.4f}; misclass={:0.4f}'.format(
        accuracy, misclass))
    plt.show()


df.hist()

y_pred = model_svm.predict(x_test)
cm1 = confusion_matrix(y_test, y_pred)
print(cm1)
total1 = sum(sum(cm1))
accuracy1 = (cm1[0, 0]+cm1[1, 1])/total1
print('Accuracy : ', accuracy1)

sensitivity1 = cm1[0, 0]/(cm1[0, 0]+cm1[0, 1])
print('Sensitivity : ', sensitivity1)

specificity1 = cm1[1, 1]/(cm1[1, 0]+cm1[1, 1])
print('Specificity : ', specificity1)

print(len(y_pred))

plot_confusion_matrix(cm1,
                      ['Did not default', 'Defaulted'],
                      title='Confusion matrix',
                      cmap=None,
                      normalize=False)

print("Accuracy {0:.2f}%".format(100*accuracy_score(y_pred, y_test)))

param_grid = [{
    'C': [0.5, 1, 10, 100],
    'gamma':['scale', 1, 0.1, 0.01, 0.001, 0.0001],
    'kernel': ['rbf']},
]

optimal_params = GridSearchCV(
    SVC(),
    param_grid,
    cv=5,
    scoring='accuracy',
    verbose=0
)
optimal_params.fit(x_train_scaled, y_train)
print(optimal_params.best_params_)

model_svm1 = SVC(random_state=2, C=0.5, gamma='scale',
                 kernel='rbf')  # support vector classifier
model_svm1.fit(x_train_scaled, y_train)

y_pred1 = model_svm1.predict(x_test)
print("Accuracy {0:.2f}%".format(100*accuracy_score(y_test, y_pred1)))
